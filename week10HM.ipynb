{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Recognition using HMM\n",
    "\n",
    "En este notebook vamos a desarrollar un etiquetado de las palabras:\n",
    "- para el español que usan el dato de CoNLL-2002 para el español, el data set completo se puede encontrar en https://github.com/teropa/nlp/tree/master/resources/corpora/conll2002\n",
    "- Tambien desarrollaremos el método tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccion de Entidades de Nombres\n",
    "\n",
    "para este procedimiento acontinuacion vamos a realizaruna secuencia de etiquetado de los nombres y anotar en\n",
    "nuestro corpus.\n",
    "\n",
    "![alt text](imagen1.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo oculto de Markov no supervizado\n",
    "\n",
    "para esto desarrollaremos y tomaremos encuenta primero solo las palabras y las\n",
    "etiquetas como se muestra acontinaucion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import nltk, nltk.classify.util, nltk.metrics\n",
    "from dataprep import conll_sentences,conll_sentence_esp, conll_words,conll_words_esp, neel_sentences, neel_words\n",
    "from helper import accuracy, entity_count\n",
    "from nltk import MaxentClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar DataSet Español\n",
    "ahora vamos a primero cargar los archivos de nuestro dataset en español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_file = './dataset/CoNLL2002/esp.train'\n",
    "testa_file = './dataset/CoNLL2002/esp.testa'\n",
    "testb_file = './dataset/CoNLL2002/esp.testb'\n",
    "\n",
    "train_words, _, train_etiquetas = conll_words_esp(train_file)\n",
    "testa_words, _, testa_etiquetas = conll_words_esp(testa_file)\n",
    "testb_words, _, testb_etiquetas = conll_words_esp(testb_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mostramos los datos cargados \n",
    "\n",
    "mostraremos los datos cargados del dataset en español, asi solo cargamos lo mas importante para este ejemplo\n",
    "- palabra, entidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] reglon: Melbourne DA LOC\n"
     ]
    }
   ],
   "source": [
    "print(\"[0] reglon:\",train_words[0],_[0],train_etiquetas[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mezcla de training , test y formar set vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acumulamos las palabras y las entidades de palabras\n",
    "\n",
    "combinado_words = train_words + testa_words + testb_words\n",
    "combinado_etiquetas = train_etiquetas + testa_etiquetas + testb_etiquetas\n",
    "\n",
    "# for para obtener el set voca\n",
    "char_set = set()\n",
    "for word in combinado_words:\n",
    "    for char in word:\n",
    "        char_set.add(char)\n",
    "etiqueta_set = set(combinado_etiquetas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training HMM no supervizado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 logprob -1540694.8438385099\n",
      "iteration 1 logprob -1105937.4315283587\n",
      "iteration 2 logprob -1101893.490903211\n",
      "iteration 3 logprob -1098056.8272231247\n",
      "iteration 4 logprob -1093746.120157142\n",
      "iteration 5 logprob -1088592.3821617411\n",
      "iteration 6 logprob -1082441.2246317966\n",
      "iteration 7 logprob -1075342.2843631073\n",
      "iteration 8 logprob -1067370.626023771\n",
      "iteration 9 logprob -1058403.5962087363\n",
      "iteration 10 logprob -1048354.4302744969\n",
      "iteration 11 logprob -1037960.2214199561\n",
      "iteration 12 logprob -1028446.0466508842\n",
      "iteration 13 logprob -1020185.1973935018\n",
      "iteration 14 logprob -1012833.001689907\n",
      "iteration 15 logprob -1005948.0716215682\n",
      "iteration 16 logprob -998915.8665790766\n",
      "iteration 17 logprob -991043.5838289928\n",
      "iteration 18 logprob -981104.17044474\n",
      "iteration 19 logprob -969750.2608120533\n",
      "iteration 20 logprob -961678.2475442089\n",
      "iteration 21 logprob -956602.4465816314\n",
      "iteration 22 logprob -953169.8160937146\n",
      "iteration 23 logprob -950822.1456024995\n",
      "iteration 24 logprob -949256.8930210482\n",
      "iteration 25 logprob -948271.1245318382\n",
      "iteration 26 logprob -947650.2013857787\n",
      "iteration 27 logprob -947227.9832336064\n",
      "iteration 28 logprob -946926.0104711109\n",
      "iteration 29 logprob -946723.3679606172\n",
      "iteration 30 logprob -946581.7346994295\n",
      "iteration 31 logprob -946478.3771421224\n",
      "iteration 32 logprob -946401.4378689028\n",
      "iteration 33 logprob -946340.6306273354\n",
      "iteration 34 logprob -946258.6633422299\n",
      "iteration 35 logprob -945980.3395039736\n",
      "iteration 36 logprob -945699.9304171115\n",
      "iteration 37 logprob -945617.8016775422\n",
      "iteration 38 logprob -945570.9137466422\n",
      "iteration 39 logprob -945535.1158718993\n",
      "iteration 40 logprob -945504.7931645251\n",
      "iteration 41 logprob -945476.6894053562\n",
      "iteration 42 logprob -945449.5729460178\n",
      "iteration 43 logprob -945425.4813896873\n",
      "iteration 44 logprob -945404.892149878\n",
      "iteration 45 logprob -945386.1287231268\n",
      "iteration 46 logprob -945368.7761931608\n",
      "iteration 47 logprob -945353.4715193132\n",
      "iteration 48 logprob -945339.8372276025\n",
      "iteration 49 logprob -945327.4252631408\n",
      "iteration 50 logprob -945316.6748376449\n",
      "iteration 51 logprob -945307.8024361465\n",
      "iteration 52 logprob -945300.2329014523\n",
      "iteration 53 logprob -945293.3558859896\n",
      "iteration 54 logprob -945286.9583618172\n",
      "iteration 55 logprob -945281.2181912534\n",
      "iteration 56 logprob -945276.2081249768\n",
      "iteration 57 logprob -945271.8454346665\n",
      "iteration 58 logprob -945268.036711008\n",
      "iteration 59 logprob -945264.7012267413\n",
      "iteration 60 logprob -945261.7555344132\n",
      "iteration 61 logprob -945259.0634050565\n",
      "iteration 62 logprob -945256.2797608938\n",
      "iteration 63 logprob -945253.1787871583\n",
      "iteration 64 logprob -945250.451008224\n",
      "iteration 65 logprob -945248.0452804285\n",
      "iteration 66 logprob -945245.7381175928\n",
      "iteration 67 logprob -945243.717908276\n",
      "iteration 68 logprob -945242.0851676896\n",
      "iteration 69 logprob -945240.7093030326\n",
      "iteration 70 logprob -945239.4854418642\n",
      "iteration 71 logprob -945238.3719480103\n",
      "iteration 72 logprob -945237.349355725\n",
      "iteration 73 logprob -945236.4043422117\n",
      "iteration 74 logprob -945235.5260911407\n",
      "iteration 75 logprob -945234.7053693724\n",
      "iteration 76 logprob -945233.9341331245\n",
      "iteration 77 logprob -945233.2052778674\n",
      "iteration 78 logprob -945232.5124585162\n",
      "iteration 79 logprob -945231.849958575\n",
      "iteration 80 logprob -945231.2125967956\n",
      "iteration 81 logprob -945230.5956665555\n",
      "iteration 82 logprob -945229.9948997232\n",
      "iteration 83 logprob -945229.4064573168\n",
      "iteration 84 logprob -945228.8269391683\n",
      "iteration 85 logprob -945228.2534138076\n",
      "iteration 86 logprob -945227.6834648147\n",
      "iteration 87 logprob -945227.1152488551\n",
      "iteration 88 logprob -945226.5475568068\n",
      "iteration 89 logprob -945225.9798771804\n",
      "iteration 90 logprob -945225.412440758\n",
      "iteration 91 logprob -945224.8462443204\n",
      "iteration 92 logprob -945224.2830368645\n",
      "iteration 93 logprob -945223.7252594985\n",
      "iteration 94 logprob -945223.1759338176\n",
      "iteration 95 logprob -945222.6385018936\n",
      "iteration 96 logprob -945222.1166213397\n",
      "iteration 97 logprob -945221.6139362346\n",
      "iteration 98 logprob -945221.133843609\n",
      "iteration 99 logprob -945220.679280496\n"
     ]
    }
   ],
   "source": [
    "# setting de modelo oculto de markov\n",
    "trainer = nltk.tag.hmm.HiddenMarkovModelTrainer(states=etiqueta_set, symbols=char_set)\n",
    "\n",
    "# entrenamiento con hmm de nltk \n",
    "modelo = trainer.train_unsupervised(testa_words, max_iterations=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluacion(test) con testb del CoNLL \n",
    "\n",
    "aqui hacemos el test y luego mostramos los primero 10 resultados del etiquetado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('La', 'O'), ('Coruña', 'O'), (',', 'O'), ('23', 'O'), ('may', 'O')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluacion del resultado\n",
    "\n",
    "testb_result = modelo.tag(testb_words)\n",
    "\n",
    "# mostrar los 10 primero del tag\n",
    "\n",
    "\n",
    "testb_result[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "testb_predecido = []\n",
    "for word, etiqueta in testb_result:\n",
    "    testb_predecido.append(etiqueta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 45355 / 51533 = 0.880116\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy(testb_etiquetas, testb_predecido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### total de etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORG: 2504\n",
      "PER: 1369\n",
      "LOC: 1409\n",
      "MISC: 896\n",
      "O: 45355\n"
     ]
    }
   ],
   "source": [
    "## mostramos total de tags\n",
    "entity_count(testb_etiquetas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo oculto de Markov condicional \n",
    "\n",
    "primero cargamos todos nuestras librerias necesarias como en la anterior pero esta vez trabajaremos com el dataSet en Ingles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## uso de nuestro Dataset CoNLL2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conll_features(index, sentence, pos, chunk):\n",
    "    \"\"\"\n",
    "    Funcion usada para extraer las caracteristicas del dataset\n",
    "    \n",
    "    'w' representa caracteristica de palabra\n",
    "    't' representa POS de etiqueta \n",
    "    'c' representa pedazo de etiqueta\n",
    "    '-n' representa  n previa caract...\n",
    "    '+n' representa n posterios caract...\n",
    "    \"\"\"\n",
    "    \n",
    "    features = {}\n",
    "    last_index = len(sentence) - 1\n",
    "    word = sentence[index]\n",
    "    word_lc = word.lower()\n",
    "    \n",
    "    # features from current word:\n",
    "    features['w'] = word\n",
    "    features['t'] = pos[index]\n",
    "    features['length'] = len(word)\n",
    "    features['uppercase'] = any(x.isupper() for x in word)\n",
    "    features['firstletter'] = word[0].isupper() and (len(word) > 1)\n",
    "    features['hasdigits'] = any(x.isdigit() for x in word)\n",
    "    features['c'] = chunk[index]\n",
    "    features['loc_flag'] = ('field' in word_lc) or ('land' in word_lc) or ('burgh' in word_lc) or ('shire' in word_lc) \n",
    "    features['hasdot'] = ('.' in word and len(word) > 1)\n",
    "    features['endsinns'] = (len(word) > 1 and word_lc[-2:] == 'ns')\n",
    "    \n",
    "    \n",
    "    # features from previous 2 words\n",
    "    if index == 0: # first word in sentence\n",
    "        features['t-2 t-1'] = '<B> <B>'\n",
    "        features['t-1'] = '<B>'\n",
    "        features['w-2'] = '<B>'\n",
    "        features['w-1'] = '<B>'\n",
    "        features['c-2 c-1'] = '<B> <B>'\n",
    "        features['c-1'] = '<B>'\n",
    "    elif index == 1: # second word in sentence\n",
    "        features['t-2 t-1'] = '<B> ' + pos[0]\n",
    "        features['t-1'] = pos[0]\n",
    "        features['w-2'] = '<B>'\n",
    "        features['w-1'] = sentence[0]\n",
    "        features['c-2 c-1'] = '<B> ' + chunk[0]\n",
    "        features['c-1'] = chunk[0]\n",
    "    else:\n",
    "        features['t-2 t-1'] = pos[index-2] + ' ' + pos[index-1]\n",
    "        features['t-1'] = pos[index-1]\n",
    "        features['w-2'] = sentence[index-2]\n",
    "        features['w-1'] = sentence[index-1]\n",
    "        features['c-2 c-1'] = chunk[index-2] + ' ' + chunk[index-1]\n",
    "        features['c-1'] = chunk[index-1]\n",
    "\n",
    "      \n",
    "    # features from posterior 2 words\n",
    "    if index == last_index: # last word in sentence\n",
    "        features['t+1 t+2'] = '<E> <E>'\n",
    "        features['t+1'] = '<E>'\n",
    "        features['w+2'] = '<E>'\n",
    "        features['w+1'] = '<E>'\n",
    "    elif index == last_index - 1: # second to last word in sentence\n",
    "        features['t+1 t+2'] = pos[last_index] + ' <E>'\n",
    "        features['t+1'] = pos[last_index]\n",
    "        features['w+2'] = '<E>'\n",
    "        features['w+1'] = sentence[last_index]\n",
    "    else:\n",
    "        features['t+1 t+2'] = pos[index+1] + ' ' + pos[index+2]\n",
    "        features['t+1'] = pos[index+1]\n",
    "        features['w+2'] = sentence[index+2]\n",
    "        features['w+1'] = sentence[index+1]\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraer oraciones con su correspondiente etiqueta del archivo CoNll2002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_train_file = './dataset/CoNLL2003/eng.train'\n",
    "c_train_sent, c_train_pos, c_train_chunk, c_train_entity = conll_sentences(c_train_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mostrar dataset \n",
    "\n",
    "ahora mostraremos los datos contenidos en el primer reglon para el ingles seguido de :\n",
    "    - (caractaristica(palabra), posicion de la palabra,pezado de palabra, entidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "EU NNP I-NP ORG\n"
     ]
    }
   ],
   "source": [
    "# mostramos una horacion encontrada\n",
    "print(\"---------------------------------------------\")\n",
    "print(c_train_sent[0][0],c_train_pos[0][0],c_train_chunk[0][0],c_train_entity[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cada oración crea conjunto de características de datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_train_data = []\n",
    "for sent, pos, chunk, entity in zip(c_train_sent, c_train_pos, c_train_chunk, c_train_entity): \n",
    "    if len(sent) != len(pos) or len(pos) != len(chunk) or len(chunk) != len(entity):\n",
    "        raise ValueError('error: CoNLL longitud de train  no coencide')  \n",
    "    for i, ent in enumerate(entity):\n",
    "        labelled_data = (get_conll_features(i, sent, pos, chunk), ent)\n",
    "        c_train_data.append(labelled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### entrenar CMM usando clasificador nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (3 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -1.60944        0.055\n",
      "             2          -0.25516        0.833\n",
      "         Final          -0.19637        0.862\n"
     ]
    }
   ],
   "source": [
    "algorithm = nltk.classify.MaxentClassifier.ALGORITHMS[0]\n",
    "memm = MaxentClassifier.train(c_train_data, algorithm, max_iter=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "c_testa_file = './dataset/CoNLL2003/eng.testa'\n",
    "c_testb_file = './dataset/CoNLL2003/eng.testb'\n",
    "c_testc_file = './dataset/CoNLL2003/eng.testc'\n",
    "\n",
    "c_testa_sent, c_testa_pos, c_testa_chunk, c_testa_entity = conll_sentences(c_testa_file)\n",
    "c_testb_sent, c_testb_pos, c_testb_chunk, c_testb_entity = conll_sentences(c_testb_file)\n",
    "c_testc_sent, c_testc_pos, c_testc_chunk, c_testc_entity = conll_sentences(c_testc_file)\n",
    "\n",
    "c_teata_truth = []\n",
    "c_testa_pred = []\n",
    "for sent, pos, chunk, entity in zip(c_testa_sent, c_testa_pos, c_testa_chunk, c_testa_entity):\n",
    "    if len(sent) != len(pos) or len(pos) != len(chunk) or len(chunk) != len(entity):\n",
    "        raise ValueError('error: CoNLL  longitud no coencide')\n",
    "    for i, ent in enumerate(entity):\n",
    "        c_teata_truth.append(ent)\n",
    "        pred = memm.classify(get_conll_features(i, sent, pos, chunk))\n",
    "        c_testa_pred.append(pred)\n",
    "\n",
    "c_teatb_truth = []\n",
    "c_testb_pred = []\n",
    "for sent, pos, chunk, entity in zip(c_testb_sent, c_testb_pos, c_testb_chunk, c_testb_entity):\n",
    "    if len(sent) != len(pos) or len(pos) != len(chunk) or len(chunk) != len(entity):\n",
    "        raise ValueError('error: CoNLL testb longitud no coencide')\n",
    "    for i, ent in enumerate(entity):\n",
    "        c_teatb_truth.append(ent)\n",
    "        pred = memm.classify(get_conll_features(i, sent, pos, chunk))\n",
    "        c_testb_pred.append(pred)\n",
    "\n",
    "c_teatc_truth = []\n",
    "c_testc_pred = []\n",
    "for sent, pos, chunk, entity in zip(c_testc_sent, c_testc_pos, c_testc_chunk, c_testc_entity):\n",
    "    if len(sent) != len(pos) or len(pos) != len(chunk) or len(chunk) != len(entity):\n",
    "        raise ValueError('error: CoNLL testc longitud no coencide')\n",
    "    for i, ent in enumerate(entity):\n",
    "        c_teatc_truth.append(ent)\n",
    "        pred = memm.classify(get_conll_features(i, sent, pos, chunk))\n",
    "        c_testc_pred.append(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluacion (accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 43917 / 51362 = 0.855048\n"
     ]
    }
   ],
   "source": [
    "accuracy(c_teata_truth, c_testa_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
